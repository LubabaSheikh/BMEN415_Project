{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.bmc.com/blogs/keras-neural-network-classification/\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Loading data\n",
    "data = pd.read_csv('Group16_ClassificationData.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af175e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41452b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Correlation between varibales using heat map\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr, \n",
    "xticklabels=corr.columns.values,\n",
    "yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can check correlation between two variables like this:\n",
    "data['BloodPressure'].corr( data[\"BMI\"])\n",
    "data[\"Pregnancies\"].corr(data[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce256148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test and training data sets\n",
    "import numpy as np\n",
    "labels=data['Outcome'] # labels is not an array. It is a column in a dataset. So we use the NumPy np.ravel() function to convert that to an array.\n",
    "features = data.iloc[:,0:8]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=features\n",
    "y=np.ravel(labels) # converting labels into an array\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42) # 20% of data for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b4d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='relu', input_shape=(8,))) # It’s (8,) since it’s a vector of 8 features. In other words its 8 x 1.\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8fd4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary crosscentropy since because out output is 1 or 0\n",
    "model.compile(loss='binary_crossentropy',\n",
    "optimizer='sgd',\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,epochs=4, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0792ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the weights for each layer\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292924e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run predictions on test data\n",
    "y_predict = np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf26b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print score/accuracy\n",
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef674aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Confusion Matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(sns.heatmap(cm, annot=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33f224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
